{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import porter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pickle.load(open(\"pickle_files/true_df.pkl\", \"rb\" ))\n",
    "true_df_backup = pickle.load(open(\"pickle_files/true_df_backup.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP\n",
      "VBZ\n",
      "VBG\n",
      "TO\n",
      "DT\n",
      "NN\n",
      "NN\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "words=pos_tag(word_tokenize(\"Who's going to that thing today?\"))\n",
    "for w in words:\n",
    "    print(w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = porter.PorterStemmer()\n",
    "stopwords = stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Removes stop words and changes word to stem words'''\n",
    "    cleaned_text = []\n",
    "    for post in text:\n",
    "        cleaned_words = []\n",
    "        for word in post.split():\n",
    "            low_word = stemmer.stem(word.lower())\n",
    "            if low_word not in stopwords:\n",
    "                cleaned_words.append(low_word)\n",
    "        cleaned_text.append(' '.join(cleaned_words))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(true_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open('clean_text.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(clean_text, picklefile)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clean_text = pickle.load(open(\"pickle_files/clean_text.pkl\", \"rb\" ))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'follow statement post verifi twitter account u.s. presid donald trump, @realdonaldtrump @potus. u.s. presid donald trump hold make america great ralli nashvil municip auditorium nashville, tennessee, u.s., may 29, 2018. reuters/leah millisth opinion express hi own. reuter edit statement confirm accuracy. @realdonaldtrump : - mitch mcconnel announc cancel senateâ€™ august recess. great, mayb democrat final get someth done accept high crime high taxes. need border security! [0002 edt] - great night republicans! congratul john cox realli big number california. win. even fake news cnn said trump impact wa realli big, much bigger ever thought possible. much big blue wave, may big red wave. work hard! [0916 edt] - gold star father, ceejay metcalf, whose great michael wa honor white house, wa fantast morn @foxandfriends. special man! [0937 edt] - fake news media unfair, vicious, wife great first lady, melania. dure recoveri surgeri report everyth near death, facelift, left w.h. (and me) n.y. virginia, abuse. fake, realli well! [0948 edt] -- sourc link: (bit.ly/2jbh4lu) (bit.ly/2jpexyr) compil bengaluru bureauour standards:th thomson reuter trust principles.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nouns(text_list):\n",
    "    no_nouns = []\n",
    "    cleaned_text = []\n",
    "    all_nouns = ['NN' or 'NNS' or 'NNP' or 'NNPS']\n",
    "    for x in text_list:\n",
    "        words=pos_tag(word_tokenize(x))\n",
    "        werdz = [s for s in words if s[-1] != 'NN']# or 'NNS' or 'NNP' or 'NNPS']\n",
    "        werdz = [s for s in werdz if s[-1] != 'NNS']\n",
    "        werdz = [s for s in werdz if s[-1] != ',']\n",
    "        werdz = [s for s in werdz if s[-1] != '.']\n",
    "        werdz = [s for s in werdz if s[-1] != ':']\n",
    "        werdz = [s for s in werdz if s[-1] != 'CD']\n",
    "        werdz = [s for s in werdz if s[-1] != '(']\n",
    "        werdz = [s for s in werdz if s[-1] != ')']\n",
    "        werdz = [s for s in werdz if s[-2] != '@']\n",
    "        werdz = [s for s in werdz if s[-2] != '[']\n",
    "        werdz = [s for s in werdz if s[-2] != ']']\n",
    "\n",
    "        #check cleaned text line from function above\n",
    "        no_nouns.append(werdz)\n",
    "    return no_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_w_no_nouns = drop_nouns(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_w_no_nouns = pickle.load(open(\"pickle_files/text_w_no_nouns.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_text = []\n",
    "clear = []\n",
    "for text in text_w_no_nouns:\n",
    "    for part in text:\n",
    "        clear.append(part[0])\n",
    "    short_text.append(' '.join(clear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open('short_text.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(short_text, picklefile)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer2 = CountVectorizer(ngram_range=(1, 4),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6)\n",
    "\n",
    "X = count_vectorizer2.fit_transform(short_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20\n",
    "n_iter = 10\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics,\n",
    "                                max_iter=n_iter,\n",
    "                                random_state=42,\n",
    "                               learning_method='online')\n",
    "X_centered_projected = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    '''Creates a list of words in each topics'''\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        print(\"Topic \", ix+1)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "quick_to_the_batmobile = display_topics(lda,count_vectorizer2.get_feature_names(),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_to_the_batmobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_centered_projected.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(X_centered_projected, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quick_to_the_batmobile.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(quick_to_the_batmobile, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered_projected_w_nouns = pickle.load(open(\"pickle_files/X_centered_projected_w_nouns\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 1  # second\n",
    "freq = 440  # Hz\n",
    "os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 3  # second\n",
    "freq = 440  # Hz\n",
    "os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
