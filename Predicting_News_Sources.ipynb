{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import porter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launches Mongo Client\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "biased_news = client.events.biased_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create news bias events\n",
    "db = client.events\n",
    "biased_news = db.biased_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicate articles\n",
    "list(biased_news.aggregate([{'$group' : {'_id': '$title', 'count': {'$sum': 1}}},\n",
    "    {'$match': {'count': {'$gte': 2}}},\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cursor\n",
    "cursor = biased_news.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads from Mongo\n",
    "true_df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete columns and drop null values\n",
    "del true_df['sub_title']\n",
    "del true_df['_id']\n",
    "true_df = true_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through dataframe and drops redundant articles\n",
    "for title in eliminate.index:\n",
    "    huh = true_df['title'] == title\n",
    "    wha = true_df[huh]\n",
    "    label = wha.index\n",
    "    true_df = true_df.drop(labels=label[1:],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of stop words\n",
    "stopwords = stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Removes stop words and changes word to stem words'''\n",
    "    cleaned_text = []\n",
    "    for post in text:\n",
    "        cleaned_words = []\n",
    "        for word in post.split():\n",
    "            low_word = word.lower()#stemmer.stem(word.lower())\n",
    "            if low_word not in stopwords:\n",
    "                cleaned_words.append(low_word)\n",
    "        cleaned_text.append(' '.join(cleaned_words))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "cleaned_text = clean_text(true_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nouns(text_list):\n",
    "    #Drops the nouns\n",
    "    no_nouns = []\n",
    "    cleaned_text = []\n",
    "    phrases = []\n",
    "    for x in text_list:\n",
    "        words = pos_tag(word_tokenize(x))\n",
    "        werdz3 = ['NNP', 'NN', 'NNP', 'NNPs', 'NNS', ',', '.', ':', '(', ')', '#', '``']\n",
    "        werdz = [s for s in words if s[-1] not in werdz3]\n",
    "        say_no = ['@','[', ']', 'amp', 'window', 'open','click', 'googletag', 'gpt', 'linkitem', 'googletag', 'getelementbyid',\n",
    "        'config', 'ldadinit', 'advertis', 'typeof', 'adsdiv', 'fjs', 'js', 'http', 'com', 'awr', 'new', 'function', 'div',\n",
    "        'ad', 'script', 'typeof', 'nr_is_logged_in', 'undefined', 'adsdiv', 'sharebox_260x60', 'ifr', 'jwplayer', 'jwp',\n",
    "        'pubdate', 'adunit', 'adwidth', 'www', 'bit.ly/2jpexyr', 'googletag.cmd.push', 'googletag.display', '\\'div-gpt-ad-1415299254516-0 \\'',\n",
    "        'open', 'opening', 'opens', 'opened', 'alabama', 'loading', 'email', 'advertise', 'apps', 'closed', 'help', 'publish',\n",
    "        'rendered', 'undefined', 'adsdiv', 'reloadcount', 'adsdiv.reloadcount', 'window.orignetid', '\\'undefined', 'window.origadsplid', 'needsrecovery',\n",
    "        'io_c3sd.ads', 'elem', 'box', 'box.offsetheight', 'box.style.marginright', 'marginright', 'ad_sharebox_260x60', 'trump',\n",
    "        'russia', 'fox', 'alerts', 'facebook', 'reuters', 'rsize', 'i+= resize /scr+ipt', 'ipt', 'scr', 'script', 'window.adsetsynccalled',\n",
    "        'adsetsynccalled', 'recoveryid', 'enablequeue', 'slotrenderended', 'beast', 'daily beast', 'clicking', 'subscribed', 'korea', 'north korea', 'south korea',\n",
    "        'breitbart', 'epa', 'labelmapping', 'comey', 'scotus', 'republicans', 'cohen', 'iran', 'syria', 'eagles', 'april', 'colorado', 'fbi',\n",
    "        'haspel', 'wedding', 'puerto', 'rico', 'puerto rico', 'huffpost', 'donald', 'don', 'nra', 'sachs', 'kelly', 'facebook', 'mohammed',\n",
    "        'div-gpt-ad-1415299254516-0 ', '\\'div-gpt-ad-1415299254516-0 \\'', '\\'slotrenderended \\'', 'slotrenderended', \n",
    "        '\\'.single-post # div-gpt-ad-1415299254516-0 \\'', 'slotrenderended', 'ldadinit', 'roseanne', 'israel', 'gaza', \n",
    "        'china', 'beijing', 'samantha', 'bee', 'valierie', 'subscribe', 'prelimmonth', 'ivanka', 'documentcloud', 'melania', \n",
    "        '(', ')', '-', ',', '.', '!', '\"', '\\'', 'var', \"\\'div-gpt-ad-1415299254516-0\", 'div-gpt-ad-1415299254516-0', '\\'.single-post'\n",
    "        '\\'slotrenderended', 'funct', '.contents', 'googletag.pubads', \"\\'slotrenderended\", \"\\'.single-post\", \"'div-gpt-ad-1403197269028-0\"\n",
    "        , 'line-height', '>', 'adtech-adspot', '//', '/style', 'overrid', 'window.adsetplid', 'adid', '||', 'adtech_call_typ',\n",
    "        'by_request', 'adtech_call_typ', 'iframe_proxy', 'ifr.offsetwidth', \"ifr.offsetheight\", \"'jquery\", \"'readytorecover\",\n",
    "        'args', \"waitforglobal\", 'arg', \"elem.contains\", \"'reloadad\", 'els', \"'adtech\", 'refreshr', \"'none\", 'collapsed', \n",
    "        'fc', 'f', 'ajax', 'needsrecoveri', 'i+=', '&', '<', '=', 'http', 'https', \"'http\", \"'http\", \"'script\", 'twitter', \n",
    "        '/.test', \"'https\", 'newsletter-inline-widget', 'margin-bottom', '15px', 'font-weight', 'font-size', '12pt', 'div.mc-field-group',\n",
    "        'padding-bottom', 'padding-right', 'input.mc-input', '.newsletter-inline-widget', 'font-family', '.wpcf7-form-control.wpcf7-text',\n",
    "        '7e7e7e', 'arial', '.wpcf7', '.wpcf7-form-control.wpcf7-text', '.newsletter.widget__contain', '.wpcf7-form-control.wpcf7-submit',\n",
    "        'box-shadow', 'text-shadow', 'letter-spacing', '.newsletter.widget__wrap', '.newsletter.widget__head', 'text-transform', \n",
    "        'max-width', 'td.first', 'padding-left', 'border-radius', 'hr.divid', 'p.subtext','==typeof', '.gettime', 'window.outerwidth',\n",
    "        'rcel.async', '/**', 'url', \"'data-timestamp\", '+new', 'd.head', 'javascript', 'php_widget-140', 'php_widget-104', '.today-on-the-show-cont',\n",
    "        '.alignleft', 'margin-right', 'margin-top', '.alignright', \"'/wp-content/uploads/static/tots.html\", \"'.today-on-the-show-content\",\n",
    "        \"'.today-on-the-show-cont\", '.html', 'img.hero-ad-speci', 'fa', 'fa-chevron-down', 'usercollapsetext', 'newsletter-side-widget', \n",
    "        'ul.stansberry-form', 'text-align', 'margin-left:0', 'margin-bottom:5px', 'border-top', '-webkit-border-radius', '-khtml-border-radius',\n",
    "        'border-width', 'border-style', 'border-right', 'padding-left:8px', '.textsiz', 'margin-top:5px', 'ul.links_list', 'img.breaking_imag', \n",
    "        'adtech_sharebox_260x60', 'advertisement', '===', 'kraken__adblock.active', 'i=0', 'id=', 'style=', '//www.documentcloud.org/documents/4434037-hhrg-115-if00-wstate-zuckerbergm-20180411.js', \n",
    "        '//assets.documentcloud.org/documents/4434037/hhrg-115-if00-wstate-zuckerbergm-20180411.pdf', 'br', 'lt', '//assets.documentcloud.org/documents/4434037/hhrg-115-if00-wstate-zuckerbergm-20180411.txt',\n",
    "        '//www.documentcloud.org/documents/4425618-van-der-zwaan.js', '//assets.documentcloud.org/documents/4425618/van-der-zwaan.pdf', '//assets.documentcloud.org/documents/4425618/van-der-zwaan.txt',\n",
    "        'subscrib', 'window.datawrapper', '.embeddeltas', 'datawrapper-height', '=typeof', '==', 'div-gpt-ad-inline_1_mobile', '.jw-player-contain', \"'jwp\",\n",
    "        '.playlist', 'episode.title', 'ns_st_st=\\\\', 'ns_st_pu=\\\\', 'ns_st_pr=\\\\', 'ns_st_ep=\\\\', 'ns_st_ia=\\\\', 'div-gpt-ad-native_mobile', 'div-gpt-ad-inline_2_mobile',\n",
    "        'div-gpt-ad-inline_3_mobile', 'ns_st_sn=\\\\', 'ns_st_en=\\\\', 'ns_st_ge=\\\\', 'ns_st_ce=\\\\', 'ns_st_ddt=\\\\', 'ns_st_tdt=\\\\', 'div-gpt-ad-native', 'div-gpt-ad-inline_4_mobile',\n",
    "        '\\\\/\\\\/www.nationalreview.com\\\\/wp-json\\\\/wp\\\\/v2\\\\/slideshow\\\\/596990', '\\\\u0000*\\\\u0000links', '\\\\/\\\\/www.nationalreview.com\\\\/wp-json\\\\/wp\\\\/v2\\\\/media', '\\\\/\\\\/www.nationalreview.com\\\\/wp-json\\\\/wp\\\\/v2\\\\/categories',\n",
    "        '\\\\/\\\\/api.w.org\\\\/term', '\\\\/\\\\/www.nationalreview.com\\\\/wp-json\\\\/wp\\\\/v2\\\\/tags', '\\\\/\\\\/www.nationalreview.com\\\\/photos\\\\/prince-harry-meghan-markle-royal-wedding\\\\/', '2fwww.nationalreview.com', 'text=harri', '2fprince-harry-meghan-markle-royal-wedding',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-26.jpg', '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-8.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-37.jpg', '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-110.jpg',\n",
    "        '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-111.jpg', '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-45.jpg',\n",
    "        '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-38.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-44.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-7.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-12.jpg', \n",
    "        '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-11.jpg', '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-43.jpg', \n",
    "        '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-21.jpg', '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-18.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-22.jpg', '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-116.jpg',\n",
    "        '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-42.jpg', '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-14.jpg',\n",
    "        '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-39.jpg', '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-54.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-112.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-106.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-25.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-46.jpg',\n",
    "        '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-24.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-29.jpg',\n",
    "        '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-48.jpg', '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-107.jpg',\n",
    "        '\\\\/\\\\/i0.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-47.jpg', '\\\\/\\\\/i2.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-33.jpg',\n",
    "        '\\\\/\\\\/i1.wp.com\\\\/www.nationalreview.com\\\\/wp-content\\\\/uploads\\\\/2018\\\\/05\\\\/harry-meghan-royal-wedding-51.jpg', 'google_ad_cli', \n",
    "        'adunit.style.display', '.length', 'google_ad_width', 'google_ad_height', 'adunit.style.margin', 'adunit.style.textalign', 'adunit.classnam',\n",
    "        '//www.activistpost.com/2018/06/israeli-selling-surveillance-systems-governments-around-world.html', \"'theactivistpost\", '.innerhtml', 'ld-ajs', 'w.ldadinit=w.ldadinit||', '//www.activistpost.com/2018/06/google-quits-drone-program-u-s-navy-wants-drone-motherships-with-help-of-a-i.html',\n",
    "        '302px', '422px', '300px', '0px', '12px', '60px', '25px', '250px', '3px', '40px', '1px', '10px','titl', '0\\\\', '//www.activistpost.com/2018/04/us-bombs-syria-to-cover-up-lack-of-evidence-on-chem-attacks-discredits-own-claims-by-doing-so.html', \n",
    "        '//www.activistpost.com/2018/05/red-nose-day-recognizes-kids-living-in-poverty-article-the-rich-get-smart-the-poor-get-technology-the-new-digital-divide-in-school-choice-highlights-part-of-the-problem.html', \n",
    "        'firstscript', 'dsqlocal', \"'trackback_url\", 'disqus_shortnam', 'fb-extra-h2', 'prelimd', 'resize', 'scr+ipt', 'paul', 'watson']\n",
    "        regex = re.compile(r\"\\S+www.nationalreview.com\\S+\")\n",
    "        linkstr = re.findall(regex, str(werdz))\n",
    "        say_no.append(linkstr)\n",
    "\n",
    "\n",
    "        werdz = ([s[-2] for s in werdz if s[-2] not in say_no and 'wp.com' not in s[-2] and 'facebook.com' not in s[-2] and\n",
    "                 '1897954795849722' not in s[-2] and '999999' not in s[-2] and \"'100\" not in s[-2] and 'prelimmonth' not in s[-2]\n",
    "                 and '5g' not in s[-2] and 'scr+ipt' not in s[-2] and 'documentcloud.org' not in s[-2] and 'www.' not in s[-2]\n",
    "                 and '10 10' not in s[-2] and 'labelmap' not in s[-2] and 'finald' not in s[-2] and '23390304' not in s[-2]\n",
    "                 and 'box.' not in s[-2] and 'label.' not in s[-2] and '.style' not in s[-2] and '10 100' not in s[-2]\n",
    "                 and '2c576' not in s[-2] and '2c90' not in s[-2] and 'ryan' not in s[-2] and 'mexico' not in s[-2] and 'todd' not in s[-2]\n",
    "                 and 'obama' not in s[-2] and 'avenatti' not in s[-2] and 'atblog' not in s[-2] and 'muslim' not in s[-2] and 'dodd' not in s[-2]\n",
    "                 and 'frank' not in s[-2] and 'rumaihi' not in s[-2] and 'bozorgmehr' not in s[-2] and 'sharafedin' not in s[-2] and 'kardashian' not in s[-2]\n",
    "                 and 'edit' not in s[-2] and 'splc' not in s[-2] and 'matt' not in s[-2] and 'agorist' not in s[-2] and 'julian' not in s[-2]\n",
    "                 and 'assange' not in s[-2] and 'wikileaks' not in s[-2] and 'giuliani' not in s[-2] and 'dinesh' not in s[-2] and 'torsion' not in s[-2]\n",
    "                 and 'freidman' not in s[-2] and 'cia' not in s[-2] and 'tmz' not in s[-2] and 'teacher' not in s[-2] and 'eric' not in s[-2] and 'texas' not in s[-2]\n",
    "                 and 'god' not in s[-2] and '1864' not in s[-2] and 'abbott' not in s[-2] and 'robert' not in s[-2] and 'derrick' not in s[-2]\n",
    "                 and 'ajdelgado13' not in s[-2] and 'sach' not in s[-2] and 'cuomo' not in s[-2] and 'orlando' not in s[-2] and 'greiten' not in s[-2] and '10 10' not in s[-2]\n",
    "                 and 'chizu' not in s[-2] and 'nomiyamaour' not in s[-2] and '000' not in s[-2] and 'yanks' not in s[-2] and 'frompovich' not in s[-2]\n",
    "                 and 'catherin' not in s[-2] and 'com' not in s[-2] and 'podcast' not in s[-2] and 'kim' not in s[-2] and 'jong' not in s[-2] and 'google_ad_client' not in s[-2]\n",
    "                 and 'bozorgmehr' not in s[-2] and 'rumaihi' not in s[-2] and 'gowdy' not in s[-2] and 'barr' not in s[-2] and 'roseanne' not in s[-2] and 'mccabe' not in s[-2]\n",
    "                 and 'andrew' not in s[-2] and 'bitcoin' not in s[-2] and 'nasa' not in s[-2] and 'nixon' not in s[-2] and 'connor' not in s[-2] and 'parenthood' not in s[-2]\n",
    "                 and 'eagle' not in s[-2] and 'sach' not in s[-2] and 'tusday' not in s[-2] and 'g7' not in s[-2] and 'god' not in s[-2] and '10pm' not in s[-2] and '1am' not in s[-2]\n",
    "                 and 'yulin' not in s[-2] and 'cruz' not in s[-2] and 'israel' not in s[-2] and '645' not in s[-2] and 'kildani' not in s[-2] and 'house' not in s[-2] and 'vin' not in s[-2]\n",
    "                 and 'mekelberg' not in s[-2] and '2016' not in s[-2] and '2017' not in s[-2] and '2018' not in s[-2] and '2019' not in s[-2]])\n",
    "        \n",
    "        #check cleaned text line from function above\n",
    "        no_nouns.append(' '.join(werdz))\n",
    "    return no_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops nouns and other terms from the text\n",
    "final_round_clean = drop_nouns(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 4),  \n",
    "                                   stop_words='english', \n",
    "                                   #token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6)\n",
    "cor_tfidf = tfidf.fit_transform(final_round_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits LSA\n",
    "lsa = TruncatedSVD(140, algorithm = 'arpack')\n",
    "corpus_lsa = lsa.fit_transform(cor_tfidf)\n",
    "corpus_lsa = Normalizer(copy=False).fit_transform(corpus_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check explained variance\n",
    "sum(lsa.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get terms\n",
    "terms = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check topics modeled\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    Terms_in_Comp = zip(terms,comp)\n",
    "    sorted_Terms = sorted(Terms_in_Comp, key = lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Topic %d:\" %i)\n",
    "    for term in sorted_Terms:\n",
    "        print(term[0])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates test-train split\n",
    "X = corpus_lsa\n",
    "y = true_df.source\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check against dummy classifer\n",
    "dumb = DummyClassifier(strategy = \"stratified\", random_state=0)\n",
    "dumb.fit(X_train, y_train)\n",
    "print(dumb.score(X_test, y_test))\n",
    "print(dumb.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits a random forest classifier\n",
    "rf2 = RandomForestClassifier(n_estimators=50)#, max_depth=36)\n",
    "rf2.fit(X_train, y_train)\n",
    "print(rf2.score(X_test, y_test))\n",
    "print(rf2.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the confusion matrix\n",
    "names = ['Fox News', 'National Review', 'Breitbart', 'Info wars', 'Global Research',\n",
    "       'Activist Post', 'Reuters', 'Associate Press',\n",
    "       'Alabama Today', 'Huffington Post', 'Daily Beast', 'Mother Jones']\n",
    "plt.figure(dpi=100)\n",
    "cm = confusion_matrix(y_test, rf2.predict(X_test), labels =names)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.colorbar();\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], ('FN', 'NR', 'B', 'IW', 'GR',\n",
    "       'ActP', 'R', 'AP',\n",
    "       'AT', 'HP', 'DB', 'MJ'))\n",
    "plt.yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], ('Fox News', 'National Review', 'Breitbart', 'Info wars', 'Global Research',\n",
    "       'Activist Post', 'Reuters', 'Associated Press',\n",
    "       'Alabama Today', 'Huffington Post', 'Daily Beast', 'Mother Jones'));\n",
    "plt.ylabel(\"True Source\")\n",
    "plt.xlabel(\"Predicted Source\");\n",
    "fmt = '.1f'\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j]),#, fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the classification report\n",
    "print(classification_report(y_test, rf2.predict(X_test), target_names=names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
